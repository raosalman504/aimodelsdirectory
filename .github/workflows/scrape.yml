name: Scrape AI Models

on:
  schedule:
    - cron: '0 */12 * * *'  # Run every 12 hours
  workflow_dispatch:  # Allow manual trigger

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
      with:
        persist-credentials: false
        fetch-depth: 0

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.12'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Create data directory if not exists
      run: |
        mkdir -p data

    - name: Run scraper
      run: |
        python -c "from scrapers.ai_models_scraper import run_spider; run_spider()"

    - name: Check if models.json exists and has content
      id: check_models
      run: |
        if [ -f "models.json" ] && [ -s "models.json" ]; then
          echo "Models file exists and has content"
          echo "has_models=true" >> $GITHUB_OUTPUT
        else
          echo "Models file is missing or empty"
          echo "has_models=false" >> $GITHUB_OUTPUT
          exit 1
        fi

    - name: Configure Git
      if: steps.check_models.outputs.has_models == 'true'
      run: |
        git config --local user.email "github-actions[bot]@users.noreply.github.com"
        git config --local user.name "github-actions[bot]"

    - name: Commit and push if changes
      if: steps.check_models.outputs.has_models == 'true'
      run: |
        git add models.json
        timestamp=$(date -u)
        git commit -m "Update models: ${timestamp}" || exit 0
        git push
